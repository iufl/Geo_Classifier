{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "import urllib, json\n",
    "\n",
    "import xml.etree.ElementTree as xml\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors, phrases\n",
    "import gensim.downloader as api\n",
    "\n",
    "from pprint import pprint\n",
    "import time\n",
    "import spacy\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import re\n",
    "import PyPDF2\n",
    "import requests\n",
    "import datetime\n",
    "import pandas\n",
    "import math\n",
    "import os\n",
    "from gsdmm.gsdmm import MovieGroupProcess\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.cluster import KMeansClusterer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import nltk\n",
    "from nltk.corpus.reader import wordnet\n",
    "\n",
    "from owslib.csw import CatalogueServiceWeb\n",
    "from owslib.fes import BBox, PropertyIsLike\n",
    "from owslib.ows import ExceptionReport\n",
    "from owslib.fes import PropertyIsEqualTo, PropertyIsLike, BBox\n",
    "from owslib import fes\n",
    "\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "import enchant\n",
    "from sklearn.cluster import KMeans;\n",
    "from sklearn.neighbors import KDTree;\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import spacy\n",
    "\n",
    "import csv\n",
    "\n",
    "import time\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FILE=\"geo_catalogue_training_data\"\n",
    "TEST_FILE=\"geo_catalogue_test_data\"\n",
    "#LANGUAGE_MODEL='../GoogleNews-vectors-negative300.bin'\n",
    "LANGUAGE_MODEL=\"solar_energy_18sept.bin\"\n",
    "\n",
    "FASTTEXT_COMMAND='fasttext'\n",
    "FASTTEXT_PATH='../../fastText-0.9.1/'\n",
    "\n",
    "MODEL_NAME='model.geo_catalogue'\n",
    "LABELED_FILE=\"geo_catalogue_labeled_data\"\n",
    "\n",
    "SEARCH_QUERY=\"solar energy\"\n",
    "DICT=enchant.Dict(\"en_US\")\n",
    "\n",
    "NUM_FEATURES=150\n",
    "\n",
    "\n",
    "NUM_LABELS=5\n",
    "\n",
    "TEMP_FILE = 'E:\\\\metadata'\n",
    "TEMP_FILE_PDF = TEMP_FILE + '.pdf'\n",
    "TEMP_FILE_TXT = TEMP_FILE + '.txt'\n",
    "MODEL_TO_TRAIN = 'biogenesis.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "import urllib, json\n",
    "\n",
    "import xml.etree.ElementTree as xml\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors, phrases\n",
    "import gensim.downloader as api\n",
    "\n",
    "from pprint import pprint\n",
    "import time\n",
    "import spacy\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import re\n",
    "import PyPDF2\n",
    "import requests\n",
    "import datetime\n",
    "import pandas\n",
    "import math\n",
    "import os\n",
    "from gsdmm.gsdmm import MovieGroupProcess\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.cluster import KMeansClusterer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import nltk\n",
    "from nltk.corpus.reader import wordnet\n",
    "\n",
    "from owslib.csw import CatalogueServiceWeb\n",
    "from owslib.fes import BBox, PropertyIsLike\n",
    "from owslib.ows import ExceptionReport\n",
    "from owslib.fes import PropertyIsEqualTo, PropertyIsLike, BBox\n",
    "from owslib import fes\n",
    "\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "import enchant\n",
    "from sklearn.cluster import KMeans;\n",
    "from sklearn.neighbors import KDTree;\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import spacy\n",
    "\n",
    "import csv\n",
    "\n",
    "import time\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download() - run only once, since the resources already dowloaded will be there"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
