{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering using keywords\n",
    "\n",
    "The first idea was to use the predefined keywords in the metadata records, to build a list of different concepts and to group the results based on these.\n",
    "\n",
    "The first step is to build a keyword list that can be used for text classifcation. In order to do this, we get the list of keywords from the metadata records and select the ones that are the similar to the search keyword (above a predefined threshold). Also, the keywords must be lemmatized in order to avoid differences between singular, plural word or case-sensitivity.\n",
    "\n",
    "For each metadata record, we are looking at the keywords that are attached and, if they are also contained in the list of the best keywords, then the preprocessed metatdata record is written in the training file, together with its corresponding best keywords, as labels. The same text will be written also in the test file, so the classifier will be able to find the best category for each metadata record.\n",
    "\n",
    "In this case, the classifier used is fasttext[1] and it uses a pre-trained model for English word vectors.\n",
    "\n",
    "[1] https://fasttext.cc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first method is based on the keywords metadata and\n",
    "#word similarity\n",
    "\n",
    "%run \"NLP_clustering.ipynb\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    csw = CatalogueServiceWeb('http://geocatalog.webservice-energy.org/geonetwork/srv/eng/csw')\n",
    "    \n",
    "    set_title = fes.PropertyIsLike('any', '')\n",
    "    filter_list = [set_title]\n",
    "\n",
    "    preprocessed_list_of_titles = []\n",
    "    csw.getrecords2(constraints=filter_list, maxrecords=2000)\n",
    "\n",
    "    fmt = '{:*^64}'.format\n",
    "    print(fmt(' Catalog information '))\n",
    "    print(\"CSW version: {}\".format(csw.version))\n",
    "    print(\"Number of datasets available: {}\".format(len(csw.records.keys())))\n",
    "    print('\\n')\n",
    "\n",
    "    keywords_set = []\n",
    "\n",
    "    for rec in csw.records:\n",
    "        keywords_set = build_keywords_set(csw.records[rec].subjects, keywords_set)\n",
    "        title = csw.records[rec].title\n",
    "        \n",
    "        if csw.records[rec].abstract != None:\n",
    "            title = title + \" \" + csw.records[rec].abstract\n",
    "\n",
    "    model, index2word_set = init_language_model()\n",
    "\n",
    "    sent1 = avg_feature_vector(SEARCH_QUERY, model, num_features=NUM_FEATURES, index2word_set=index2word_set)\n",
    "    similarity_index = 0.5\n",
    "    count = 0\n",
    "    while similarity_index < 1:\n",
    "        best_keywords = get_best_keywords_from_list(keywords_set, sent1, similarity_index)\n",
    "        build_training_test_database(csw.records, best_keywords)\n",
    "        train_fasttext_classifer()\n",
    "        run_classifier_on_data(count)\n",
    "        show_results(str(similarity_index), count)\n",
    "        similarity_index += 0.1\n",
    "        count+= 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(\"0.8\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
