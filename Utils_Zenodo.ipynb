{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"__imports__.ipynb\"\n",
    "\n",
    "\n",
    "def get_zenodo_entries(query):\n",
    "\n",
    "    ZENODO_ACCESS_TOKEN = 'k3Sb7fEuIpBB41nXG7RQyXJhp77mWZtp4mmUahMQasDXOPHyLdjpgGiPLbGF'\n",
    "\n",
    "    # Get articles from zenodo from a search query and compare them with the ones already saved\n",
    "    r = requests.get('https://zenodo.org/api/records/',\n",
    "                     params={'access_token': ZENODO_ACCESS_TOKEN, 'q' : \"\\\"\" + query + \"\\\"\"})\n",
    "\n",
    "    database = r.json()\n",
    "    today =  datetime.datetime.combine(datetime.date.today(), datetime.time(0, 0))\n",
    "\n",
    "    total_articles = []\n",
    "    \n",
    "    while (r.status_code == 200) :\n",
    "        for article in database['hits']['hits']:\n",
    "            # check if the article has an identifier\n",
    "            if not 'doi' in article:\n",
    "                continue\n",
    "            # check if the article is open and can be downloaded\n",
    "            if (article['metadata']['access_right'] == 'embargoed'):\n",
    "                embargo_date =  datetime.datetime.strptime(article['metadata']['embargo_date'], '%Y-%m-%d')\n",
    "                if (embargo_date > today):\n",
    "                    continue\n",
    "            elif (article['metadata']['access_right'] != 'open'):\n",
    "                continue\n",
    "\n",
    "            # if there is metadata missing, go to the next entry\n",
    "            if 'files' not in article:\n",
    "                continue\n",
    "            #keep only pdf files, since they can be transformed to text\n",
    "            if article['files'][0]['type'] != 'pdf':\n",
    "                continue\n",
    "            total_articles.append(article)\n",
    "            \n",
    "            \n",
    "        # go to the next page of results\n",
    "        if 'next' in database['links']:\n",
    "            r = requests.get(database['links']['next'], params={'access_token': ZENODO_ACCESS_TOKEN})\n",
    "            database = r.json()\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return total_articles\n",
    "    \n",
    "\n",
    "    \n",
    "# Download the PDF file, pre-process the text and save it in the text file\n",
    "def save_pdf_and_get_text (link_to_download, filename=TEMP_FILE_PDF):\n",
    "\n",
    "    keywords = []\n",
    "    response = requests.get(link_to_download)\n",
    "\n",
    "    # keep abbreviations, they will be replaced after cleanup\n",
    "    # by the corresponding words sequence\n",
    "    abbr_lower = [abbr.lower() for abbr in abbreviations]\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    text = cmdExtractPdfText()\n",
    "    text = prepareDescription(text, keepwords, abbr_lower)\n",
    "    text = replace_abbrevations(text, abbreviations)\n",
    "    return text.split(' ')\n",
    "\n",
    "\n",
    "# Call the pdftotext Linux utility to transform the content of the pdf file into text\n",
    "# This is the fastest way of getting ata\n",
    "def cmdExtractPdfText(filePath=TEMP_FILE_TXT):\n",
    "    subprocess.call((\"pdftotext \" + TEMP_FILE_PDF + \" \" + filePath).split())\n",
    "    text = \"\"\n",
    "    with open(filePath, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# This is the alternative way, there is a PyPDF2 module in python that read files,\n",
    "# but it doesn't get them well everytime. It also requires qpdf utulity to repaid the files,\n",
    "# since at the first try, it returns an error, considering the file corrupt\n",
    "def extractPdfText(filePath=''):\n",
    "\n",
    "    # Open the pdf file in read binary mode.\n",
    "    fileObject = open(filePath, 'rb')\n",
    "\n",
    "    try:\n",
    "        # Create a pdf reader .\n",
    "        pdfFileReader = PyPDF2.PdfFileReader(fileObject, strict=False)\n",
    "    \n",
    "    except:\n",
    "        subprocess.call((\"qpdf \" + TEMP_FILE_PDF + \" \" + TEMP_FILE +\".repaired.pdf\").split())\n",
    "        subprocess.call(\"cp \" + TEMP_FILE +\".repaired.pdf\" + TEMP_FILE +\".repaired.pdf\".split())\n",
    "        pdfFileReader = PyPDF2.PdfFileReader(fileObject, strict=False)\n",
    "\n",
    "    text = ''\n",
    "        \n",
    "    # Get total pdf page number.\n",
    "    try:\n",
    "        totalPageNumber = pdfFileReader.numPages\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "    # Print pdf total page number.\n",
    "    print('This pdf file contains totally ' + str(totalPageNumber) + ' pages.')\n",
    "\n",
    "    currentPageNumber = 0\n",
    "\n",
    "    # Loop in all the pdf pages.\n",
    "    while(currentPageNumber < totalPageNumber):\n",
    "\n",
    "        # Get the specified pdf page object.\n",
    "        try:\n",
    "            pdfPage = pdfFileReader.getPage(currentPageNumber)\n",
    "            # Get pdf page text.\n",
    "            # print(str(pdfPage.extractText()))\n",
    "            page_text = ''\n",
    "            try:\n",
    "                page_text = str(pdfPage.extractText())\n",
    "            except:\n",
    "                print(\"Cannot extract text from page %d\" %currentPageNumber)\n",
    "            text = text + ' ' + page_text\n",
    "        except:\n",
    "            print(\"No content page %d\" %currentPageNumber)\n",
    "\n",
    "        # Process next page.\n",
    "        currentPageNumber += 1\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresults = get_zenodo_entries(\"solar irradiance\")\\n\\ndocuments = []\\n\\ndocuments.extend(get_zenodo_entries(\"photovoltaic\"))\\ndocuments.extend(get_zenodo_entries(\"Renewable Energy\"))\\ndocuments.extend(get_zenodo_entries(\"solar pond\"))\\ndocuments.extend(get_zenodo_entries(\"solar observations\"))\\n\\nsearch_doi = [article[\\'doi\\'] for article in results]\\ndatabase_doi = [article[\\'doi\\'] for article in documents]\\n    \\ndatabase_doi = [doi for doi in database_doi if doi not in search_doi]\\n\\n# we already have the fies downloaded\\n# so look for them in the /tmp folder\\n# otherwise, download it\\nfor doc in documents:\\n    if doc[\\'doi\\'] in database_doi:\\n        mod_doi = doc[\\'doi\\'].replace(\\'/\\', \\'-\\')\\n\\n        #look in tmp folder if there is a file containing the doi\\n        # if there is, just read the file and move to the next entry\\n        if os.path.isfile(\\'/tmp/\\' + mod_doi + \".txt\"):\\n            continue\\n\\n        doc_list = save_pdf_and_get_text(doc[\\'files\\'][0][\\'links\\'][\\'self\\'])\\n        # overwrite the doi temporary file\\n        with open(\\'/tmp/\\' + mod_doi + \".txt\", \\'w\\') as f:\\n            f.write(\\' \\'.join(doc_list))\\n            f.close()\\n\\n#get each file in the folder and build a corpus based on those articles\\ncorpus = []\\nfor doi in database_doi:\\n    mod_doi = doi.replace(\\'/\\', \\'-\\')\\n    with open(\\'/tmp/\\' + mod_doi + \".txt\", \\'r\\') as f:\\n        corpus.append(f.read().split())\\n    \\nprint(corpus)\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "results = get_zenodo_entries(\"solar irradiance\")\n",
    "\n",
    "documents = []\n",
    "\n",
    "documents.extend(get_zenodo_entries(\"photovoltaic\"))\n",
    "documents.extend(get_zenodo_entries(\"Renewable Energy\"))\n",
    "documents.extend(get_zenodo_entries(\"solar pond\"))\n",
    "documents.extend(get_zenodo_entries(\"solar observations\"))\n",
    "\n",
    "search_doi = [article['doi'] for article in results]\n",
    "database_doi = [article['doi'] for article in documents]\n",
    "    \n",
    "database_doi = [doi for doi in database_doi if doi not in search_doi]\n",
    "\n",
    "# we already have the fies downloaded\n",
    "# so look for them in the /tmp folder\n",
    "# otherwise, download it\n",
    "for doc in documents:\n",
    "    if doc['doi'] in database_doi:\n",
    "        mod_doi = doc['doi'].replace('/', '-')\n",
    "\n",
    "        #look in tmp folder if there is a file containing the doi\n",
    "        # if there is, just read the file and move to the next entry\n",
    "        if os.path.isfile('/tmp/' + mod_doi + \".txt\"):\n",
    "            continue\n",
    "\n",
    "        doc_list = save_pdf_and_get_text(doc['files'][0]['links']['self'])\n",
    "        # overwrite the doi temporary file\n",
    "        with open('/tmp/' + mod_doi + \".txt\", 'w') as f:\n",
    "            f.write(' '.join(doc_list))\n",
    "            f.close()\n",
    "\n",
    "#get each file in the folder and build a corpus based on those articles\n",
    "corpus = []\n",
    "for doi in database_doi:\n",
    "    mod_doi = doi.replace('/', '-')\n",
    "    with open('/tmp/' + mod_doi + \".txt\", 'r') as f:\n",
    "        corpus.append(f.read().split())\n",
    "    \n",
    "print(corpus)\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
