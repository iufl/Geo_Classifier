{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import gensim\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')  # Let's not pay heed to them right now\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.corpora import Dictionary\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%run NLP_clustering.ipynb\n",
    "\n",
    "def evaluate_bar_graph(coherences, indices):\n",
    "    \"\"\"\n",
    "    Function to plot bar graph.\n",
    "    \n",
    "    coherences: list of coherence values\n",
    "    indices: Indices to be used to mark bars. Length of this and coherences should be equal.\n",
    "    \"\"\"\n",
    "    assert len(coherences) == len(indices)\n",
    "    n = len(coherences)\n",
    "    x = np.arange(n)\n",
    "    plt.bar(x, coherences, width=0.2, tick_label=indices, align='center')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Coherence Value')\n",
    "\n",
    "def ret_top_model():\n",
    "    \"\"\"\n",
    "    Since LDAmodel is a probabilistic model, it comes up different topics each time we run it. To control the\n",
    "    quality of the topic model we produce, we can see what the interpretability of the best topic is and keep\n",
    "    evaluating the topic model until this threshold is crossed. \n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lm: Final evaluated topic model\n",
    "    top_topics: ranked topics in decreasing order. List of tuples\n",
    "    \"\"\"\n",
    "    top_topics = [(0, 0)]\n",
    "    while top_topics[0][1] < 0.97:\n",
    "        lm = LdaModel(corpus=corpus, id2word=dictionary)\n",
    "        coherence_values = {}\n",
    "        for n, topic in lm.show_topics(num_topics=-1, formatted=False):\n",
    "            topic = [word for word, _ in topic]\n",
    "            cm = CoherenceModel(topics=[topic], texts=train_texts, dictionary=dictionary, window_size=10)\n",
    "            coherence_values[n] = cm.get_coherence()\n",
    "        top_topics = sorted(coherence_values.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return lm, top_topics\n",
    "\n",
    "\n",
    "def topic_prob_extractor(gensim_hdp):\n",
    "    shown_topics = gensim_hdp.show_topics(num_topics=-1, formatted=False)\n",
    "    topics_nos = [x[0] for x in shown_topics ]\n",
    "    weights = [ sum([item[1] for item in shown_topics[topicN][1]]) for topicN in topics_nos ]\n",
    "\n",
    "    return pd.DataFrame({'topic_id' : topics_nos, 'weight' : weights})\n",
    "\n",
    "def evaluate_graph(dictionary, corpus, texts, limit):\n",
    "    \"\"\"\n",
    "    Function to display num_topics - LDA graph using c_v coherence\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    limit : topic limit\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    lm_list : List of LDA topic models\n",
    "    c_v : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    c_v = []\n",
    "    lm_list = []\n",
    "    for num_topics in range(1, limit):\n",
    "        lm = gensim.models.LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "        lm_list.append(lm)\n",
    "        cm = gensim.models.CoherenceModel(model=lm, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        c_v.append(cm.get_coherence())\n",
    "        \n",
    "    # Show graph\n",
    "    x = range(1, limit)\n",
    "    plt.plot(x, c_v)\n",
    "    plt.xlabel(\"num_topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend((\"c_v\"), loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return lm_list, c_v\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    csw = CatalogueServiceWeb('http://geocatalog.webservice-energy.org/geonetwork/srv/eng/csw')\n",
    "    set_title = fes.PropertyIsLike('any', '')#SEARCH_QUERY)\n",
    "    filter_list = [set_title]\n",
    "\n",
    "    csw.getrecords2(constraints=filter_list, maxrecords=2000)\n",
    "\n",
    "    fmt = '{:*^64}'.format\n",
    "    print(fmt(' Catalog information '))\n",
    "    print(\"CSW version: {}\".format(csw.version))\n",
    "    print(\"Number of datasets available: {}\".format(len(csw.records.keys())))\n",
    "    print('\\n')\n",
    "\n",
    "    original_list_of_titles = []\n",
    "    preprocessed_list_of_titles = []\n",
    "    identifiers = []\n",
    "    word2vec_number_list = []\n",
    "    \n",
    "    for rec in csw.records:\n",
    "        original_list_of_titles.append(csw.records[rec].title)\n",
    "        identifiers.append(csw.records[rec].identifier)\n",
    "        title = prepareDescription(csw.records[rec].title, keepwords)\n",
    "        if csw.records[rec].abstract != '':\n",
    "            abstract = prepareDescription(csw.records[rec].abstract, keepwords)\n",
    "            title = title + \" \" + abstract\n",
    "        \n",
    "        #sent = avg_feature_vector(keyw, model, num_features=NUM_FEATURES, index2word_set=index2word_set)\n",
    "        #if len(title) != 0:\n",
    "        preprocessed_list_of_titles.append(title.split())\n",
    "        #word2vec_number_list.append(sent)\n",
    "\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "    preprocessed_list_of_titles = lemmatization(preprocessed_list_of_titles, nlp)\n",
    "    dictionary = Dictionary(preprocessed_list_of_titles)\n",
    "    \n",
    "    corpus = [dictionary.doc2bow(doc) for doc in preprocessed_list_of_titles]\n",
    "    \n",
    "    lsimodel = LsiModel(corpus=corpus, num_topics=10, id2word=dictionary)\n",
    "    lsitopics = lsimodel.show_topics(formatted=False)\n",
    "    print(\"------------------------------LSI----------------------------------\")\n",
    "    print(lsimodel.show_topics(10))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    \n",
    "    hdpmodel = HdpModel(corpus=corpus, id2word=preprocessed_list_of_titles)\n",
    "    hdptopics = hdpmodel.show_topics(formatted=False)\n",
    "    data_frame = topic_prob_extractor(hdpmodel)\n",
    "    data_frame = data_frame.sort_values(by='weight', ascending=False)\n",
    "    print(\"------------------------------HDP----------------------------------\")\n",
    "    print(data_frame)\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    \n",
    "    train_texts = preprocessed_list_of_titles\n",
    "\n",
    "    lm, top_topics = ret_top_model()\n",
    "    print(\"------------------------------LDA----------------------------------\")\n",
    "    print(top_topics[:5])\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    \n",
    "    lmlist, c_v = evaluate_graph(dictionary=dictionary, corpus=corpus, texts=train_texts, limit=10)\n",
    "    lmtopics = lmlist[5].show_topics(formatted=False)\n",
    "    ldatopics = ldamodel.show_topics(formatted=False)\n",
    "    \n",
    "    \n",
    "    lda_lsi_topics = [[word for word, prob in lm.show_topic(topicid)] for topicid, c_v in top_topics]\n",
    "    \n",
    "    lsitopics = [[word for word, prob in topic] for topicid, topic in lsitopics]\n",
    "\n",
    "    hdptopics = [[word for word, prob in topic] for topicid, topic in hdptopics]\n",
    "\n",
    "    ldatopics = [[word for word, prob in topic] for topicid, topic in ldatopics]\n",
    "\n",
    "    lmtopics = [[word for word, prob in topic] for topicid, topic in lmtopics]\n",
    "\n",
    "    \n",
    "    lsi_coherence = CoherenceModel(topics=lsitopics[:10], texts=train_texts, dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "    hdp_coherence = CoherenceModel(topics=hdptopics[:10], texts=train_texts, dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "    lda_coherence = CoherenceModel(topics=ldatopics, texts=train_texts, dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "    lm_coherence = CoherenceModel(topics=lmtopics, texts=train_texts, dictionary=dictionary, window_size=10).get_coherence()\n",
    "\n",
    "    lda_lsi_coherence = CoherenceModel(topics=lda_lsi_topics[:10], texts=train_texts, dictionary=dictionary, window_size=10).get_coherence()\n",
    "    \n",
    "    evaluate_bar_graph([lsi_coherence, hdp_coherence, lda_coherence, lm_coherence, lda_lsi_coherence],\n",
    "                   ['LSI', 'HDP', 'LDA', 'LDA_Mod', 'LDA_LSI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
